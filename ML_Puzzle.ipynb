{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK3LgUgqcRJ6"
      },
      "outputs": [],
      "source": [
        "!unzip 'data.zip'     # unzipping training data along with cross validation data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Part 1 - Data Preprocessing\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True\n",
        "                                   )\n",
        "training_set = train_datagen.flow_from_directory('/content/data/Train Data',\n",
        "                                                 target_size = (200, 200),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/data/Test Data',\n",
        "                                            target_size = (200, 200),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "SPI6demqceIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# Building the  Convolutional Neural Network\n",
        "classifier = Sequential([\n",
        "             Convolution2D(64, 3, 3, input_shape = (200, 200, 3), activation = 'relu'),\n",
        "             MaxPooling2D(pool_size = (2, 2)),\n",
        "             Convolution2D(32, 3, 3, activation = 'relu'),\n",
        "             MaxPooling2D(pool_size = (2, 2)),\n",
        "             Flatten(),\n",
        "             Dense( 128, activation = 'relu'),\n",
        "             Dense( 64, activation = 'relu'),\n",
        "             Dense( 1, activation = 'sigmoid')])\n"
      ],
      "metadata": {
        "id": "LQO3QEfRcaF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])"
      ],
      "metadata": {
        "id": "0TciQW_IchbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "id": "pVey6APucobE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = classifier.evaluate(test_set)"
      ],
      "metadata": {
        "id": "WZCRg1czcr7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
        "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
      ],
      "metadata": {
        "id": "n3gUTp5PcwNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'TestSet.zip'"
      ],
      "metadata": {
        "id": "14I9lhSUdSHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from PIL import Image as PImage\n",
        "import numpy as np\n",
        "def loadImages(path):\n",
        "    # return array of images\n",
        "\n",
        "    imagesList = listdir(path)\n",
        "    y_pred = []\n",
        "    for image in imagesList:\n",
        "        pathimg = path + image\n",
        "        test_image = tf.keras.utils.load_img(pathimg, target_size = (200, 200))\n",
        "        test_image = tf.keras.utils.img_to_array(test_image)\n",
        "        test_image = np.expand_dims(test_image, axis = 0)\n",
        "        result = classifier.predict(test_image)\n",
        "        training_set.class_indices\n",
        "        if result[0][0] == 1:\n",
        "          prediction = 1\n",
        "        else:\n",
        "          prediction = 0\n",
        "        y_pred.append(prediction)\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "wE0xfizYhzqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/TestSet/'\n",
        "y_pred = loadImages(path)"
      ],
      "metadata": {
        "id": "1kqo491Ah2qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(y_pred[i])"
      ],
      "metadata": {
        "id": "rkcL71i7h5-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}